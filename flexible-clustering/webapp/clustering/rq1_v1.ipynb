{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb828638",
   "metadata": {},
   "source": [
    "# RQ1 Evaluation Notebook\n",
    "\n",
    "Internal clustering metrics (silhouette, tree‚Äêstructure, entropy) using:\n",
    "- Semantic similarity (precomputed matrix)\n",
    "- Baseline (Levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup path to include webapp/\n",
    "import sys, os\n",
    "project_root = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(project_root, 'webapp'))\n",
    "print('PYTHONPATH[0] =', sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Imports\n",
    "from clustering.clustering_algorithms import run_clustering, filtered_commands_global\n",
    "from clustering.preprocessing import abstract_command_line_substitution\n",
    "from clustering.similarity import distance_func\n",
    "from clustering.evaluation_metrics import (evaluate_clustering, extract_labels_from_tree, compute_tree_metrics, compute_purpose_entropy)\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a390cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Run clustering on sample\n",
    "cluster_results, cluster_tree = run_clustering(size=2000)  # adjust for speed\n",
    "# 4) Build abstracts\n",
    "abstracts = [abstract_command_line_substitution(cmd) for _, cmd in filtered_commands_global]\n",
    "print(f'Clustered {len(abstracts)} commands into {len(cluster_results)} cluster entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b9d35",
   "metadata": {},
   "source": [
    "---\n",
    "## A) Semantic distance via matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed similarity\n",
    "from clustering.load_data import load_command_resources\n",
    "_, sim_df, _, _ = load_command_resources()\n",
    "# Align with abstracts\n",
    "sim_df = sim_df.loc[abstracts, abstracts]\n",
    "# Build distance matrix = 1 - similarity\n",
    "dist_mat = 1.0 - sim_df.values\n",
    "print('Distance matrix shape:', dist_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472066b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute silhouette (precomputed)\n",
    "from sklearn.metrics import silhouette_score\n",
    "labels = extract_labels_from_tree(cluster_tree, len(abstracts))\n",
    "sil_sem = silhouette_score(dist_mat, labels, metric='precomputed')\n",
    "print(f'Silhouette (semantic): {sil_sem:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other metrics\n",
    "tree_metrics = compute_tree_metrics(cluster_tree)\n",
    "entropy_metrics = compute_purpose_entropy(cluster_results)\n",
    "print('Tree metrics:', tree_metrics)\n",
    "print('Entropy metrics:', entropy_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ac31c",
   "metadata": {},
   "source": [
    "---\n",
    "## B) Using evaluate_clustering + dist_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09efa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dist_func from sim_df\n",
    "def matrix_dist(a, b): return 1.0 - sim_df.at[a, b]\n",
    "full_sem = evaluate_clustering(abstracts, cluster_results, cluster_tree, matrix_dist)\n",
    "print('Full semantic metrics:')\n",
    "print(pd.Series(full_sem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Levenshtein\n",
    "!pip install python-Levenshtein\n",
    "from Levenshtein import distance as lev_dist\n",
    "def baseline(a,b): return lev_dist(a,b)/max(len(a),len(b),1)\n",
    "baseline_metrics = evaluate_clustering(abstracts, cluster_results, cluster_tree, baseline)\n",
    "print('Baseline metrics:')\n",
    "print(pd.Series(baseline_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8461a8",
   "metadata": {},
   "source": [
    "---\n",
    "## C) Compare & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600315a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate\n",
    "df = pd.DataFrame([full_sem, baseline_metrics], index=['Semantic','Baseline'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371df4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df.index, df['silhouette'])\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Semantic vs Baseline')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
