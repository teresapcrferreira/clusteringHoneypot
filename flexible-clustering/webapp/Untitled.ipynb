{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4af2a4-b0a2-4cba-8526-10ea59ebe261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to PYTHONPATH: /home/tferreira/Documents/Clustering/flexible-clustering/webapp/webapp\n"
     ]
    }
   ],
   "source": [
    "# 1) Setup path to include webapp/ as a package\n",
    "import sys, os\n",
    "project_root = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(project_root, 'webapp'))\n",
    "print('Added to PYTHONPATH:', sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae04aa28-ab24-4c4d-b39b-fc4bba2c03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make sure your project modules are on PYTHONPATH.\n",
    "# If this notebook lives outside webapp/, adjust the path below:\n",
    "# import sys; sys.path.append(\"/full/path/to/flexible-clustering/webapp\")\n",
    "\n",
    "from clustering.clustering_algorithms import fetch_cowrie_data\n",
    "from clustering.preprocessing      import is_real_command, abstract_command_line_substitution\n",
    "from clustering.similarity                     import distance_func\n",
    "from fish.fishdbc                   import FISHDBC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c673284-57af-4129-bdc0-68f4bb50b43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9958 commands for clustering.\n"
     ]
    }
   ],
   "source": [
    "# 2. Configure your data range and honeypot type.\n",
    "honeypot_type = \"cowrie\"\n",
    "from_date    = \"2025-01-01T00:00:00\"  # ISO format, inclusive\n",
    "to_date      = \"2025-07-17T23:59:59\"  # up to yesterday\n",
    "\n",
    "# 3. Fetch raw logs and filter/abstract\n",
    "df = fetch_cowrie_data(honeypot_type, from_date, to_date, size=10000)\n",
    "df = df[df['input'].notna()]\n",
    "\n",
    "# Keep only “real” shell commands\n",
    "filtered = [(i, cmd) for i, cmd in enumerate(df['input'].values)\n",
    "            if is_real_command(cmd)]\n",
    "indices, raw_cmds = zip(*filtered)\n",
    "abstracts = [abstract_command_line_substitution(cmd) for cmd in raw_cmds]\n",
    "\n",
    "print(f\"Loaded {len(abstracts)} commands for clustering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04886de-ece4-4eaf-b87f-de05e93179a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [-1  0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# 4. Run FISHDBC on your abstracts\n",
    "dist_fn = distance_func()          # your semantic distance\n",
    "fish   = FISHDBC(dist_fn)\n",
    "fish.update(abstracts)\n",
    "\n",
    "# cluster() returns (labels, probs, stabilities, condensed_tree, slt, mst)\n",
    "labels, *_ = fish.cluster()\n",
    "labels = np.array(labels)\n",
    "print(f\"Cluster labels: {np.unique(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a1f256-3ed8-4a11-987c-a1ecda694c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, 10,  7, ...,  6, -1,  4], shape=(9958,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50fe2c6-9974-4ead-8193-9a053077786d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n):\n\u001b[0;32m----> 7\u001b[0m         d \u001b[38;5;241m=\u001b[39m \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstracts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         D[i, j] \u001b[38;5;241m=\u001b[39m D[j, i] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m     10\u001b[0m D \u001b[38;5;241m=\u001b[39m D \u001b[38;5;241m-\u001b[39m D\u001b[38;5;241m.\u001b[39mmin()\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/clustering/similarity.py:61\u001b[0m, in \u001b[0;36mdistance_func.<locals>.<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdistance_func\u001b[39m():\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a lambda function that computes the distance between two abstracted command strings\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    using the global similarity matrix loaded at module-level.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        Callable: A two-argument function (cmd1, cmd2) → distance (float).\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[43mgeometric_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/clustering/similarity.py:33\u001b[0m, in \u001b[0;36mgeometric_distance\u001b[0;34m(cmd1, cmd2, sim_matrix)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     32\u001b[0m units1 \u001b[38;5;241m=\u001b[39m group_commands_and_flags(cmd1\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m---> 33\u001b[0m units2 \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_commands_and_flags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(units1), \u001b[38;5;28mlen\u001b[39m(units2))\n\u001b[1;32m     35\u001b[0m sims \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/clustering/preprocessing.py:94\u001b[0m, in \u001b[0;36mgroup_commands_and_flags\u001b[0;34m(abstract_cmd)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classify_argument(token)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPERATOR\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     95\u001b[0m     grouped[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrouped[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5. Build the pairwise distance matrix (O(n²) cost!)\n",
    "n = len(abstracts)\n",
    "D = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        d = dist_fn(abstracts[i], abstracts[j])\n",
    "        D[i, j] = D[j, i] = d\n",
    "\n",
    "D = D - D.min()\n",
    "# 6. Compute overall silhouette score\n",
    "sil_avg = silhouette_score(D, labels, metric=\"precomputed\")\n",
    "print(f\"Average silhouette score: {sil_avg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e080e-3355-47df-a037-5fa57730f100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba3ed3dd-f62e-4216-97e8-aa6ec47aa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_df = pd.read_csv(\"databases/UpdatedSimilarity.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab0469c7-f0c2-409d-8690-55669ee71e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.load_data import load_command_resources\n",
    "\n",
    "# this gives you (… , similarity_matrix, …)\n",
    "_, similarity_matrix, _, _ = load_command_resources()\n",
    "dist_fn = distance_func()   # wraps geometric_distance(cmd1, cmd2, similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e65754a-c371-45ee-a410-d12f03b27786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the token–token matrix\n",
    "S_tokens = pd.read_csv(\"databases/UpdatedSimilarity.csv\", index_col=0)\n",
    "\n",
    "# convert to nested dict[str,dict[str,float]]\n",
    "similarity_matrix = {\n",
    "    token: S_tokens.loc[token].to_dict()\n",
    "    for token in S_tokens.index\n",
    "}\n",
    "\n",
    "# now recreate your dist_fn\n",
    "from clustering.similarity import geometric_distance\n",
    "def dist_fn(x, y):\n",
    "    return geometric_distance(x, y, similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08b8d6ae-a71e-4905-8d70-e5770db7decb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(abstracts)[:, \u001b[38;5;28;01mNone\u001b[39;00m]   \u001b[38;5;66;03m# shape (N,1), each entry is a string\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# compute the N×N distance matrix in parallel\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# sanity: zero out the diagonal\u001b[39;00m\n\u001b[1;32m     15\u001b[0m np\u001b[38;5;241m.\u001b[39mfill_diagonal(D, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2477\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   2475\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 2477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1965\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1963\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n\u001b[1;32m   1964\u001b[0m ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1965\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreading\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_n_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1971\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;66;03m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m     np\u001b[38;5;241m.\u001b[39mfill_diagonal(ret, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Clustering/flexible-clustering/webapp/.venv/lib/python3.10/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score\n",
    "\n",
    "# abstracts is your list of N=9958 abstracted commands, in the same order as labels\n",
    "X = np.array(abstracts)[:, None]   # shape (N,1), each entry is a string\n",
    "\n",
    "# compute the N×N distance matrix in parallel\n",
    "D = pairwise_distances(\n",
    "    X,\n",
    "    metric=lambda a, b: dist_fn(a[0], b[0]),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# sanity: zero out the diagonal\n",
    "np.fill_diagonal(D, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e983294-021b-4b5a-9752-f8463353afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate silhouette (1 000 samples): 0.502\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Number of samples\n",
    "N = len(abstracts)\n",
    "\n",
    "# 1) Build a numeric “feature” array of shape (N,1) whose only feature is the sample index\n",
    "X_idx = np.arange(N, dtype=int).reshape(-1, 1)\n",
    "\n",
    "# 2) Define a metric that maps back to your command strings\n",
    "def idx_dist(a, b):\n",
    "    # a and b are 1‑d numpy arrays of length 1, dtype float\n",
    "    i = int(a[0])\n",
    "    j = int(b[0])\n",
    "    return dist_fn(abstracts[i], abstracts[j])\n",
    "\n",
    "# 3) Call silhouette_score without precomputing the full D\n",
    "sil = silhouette_score(\n",
    "    X_idx,\n",
    "    labels,\n",
    "    metric=idx_dist,\n",
    "    sample_size=1000,    # sample up to 1000 points to speed things up\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Approximate silhouette (1 000 samples): {sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c4d9f-6b23-4c52-99f4-e860b370e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples= 3, min_cluster_size= 3, method=eom   → silhouette=0.495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from clustering.similarity import distance_func\n",
    "from fish.fishdbc         import FISHDBC\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Prepare the “index” feature array and the idx→command metric\n",
    "# -----------------------------------------------------------------------------\n",
    "N = len(abstracts)\n",
    "X_idx = np.arange(N, dtype=int).reshape(-1, 1)\n",
    "\n",
    "def idx_dist(a, b):\n",
    "    i = int(a[0])\n",
    "    j = int(b[0])\n",
    "    return dist_fn(abstracts[i], abstracts[j])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Sweep FISHDBC parameters and record the best silhouette\n",
    "# -----------------------------------------------------------------------------\n",
    "best = {\n",
    "    'min_samples': None,\n",
    "    'min_cluster_size': None,\n",
    "    'method': None,\n",
    "    'sil_score': -1.0\n",
    "}\n",
    "\n",
    "for min_s in [3, 5, 10, 20]:\n",
    "    # you can also try different m, ef here:\n",
    "    fish = FISHDBC(distance_func(),\n",
    "                   min_samples=min_s,\n",
    "                   m=5, ef=50,\n",
    "                   vectorized=False)\n",
    "    # build the index+MST once per setting\n",
    "    fish.update(abstracts)\n",
    "    \n",
    "    for min_cs in [min_s, max(min_s*2, 1), max(min_s*5, 1)]:\n",
    "        for method in ['eom', 'leaf']:\n",
    "            labels, *_ = fish.cluster(\n",
    "                min_cluster_size=min_cs,\n",
    "                cluster_selection_method=method,\n",
    "            )\n",
    "            \n",
    "            # compute (sampled) silhouette\n",
    "            sil = silhouette_score(\n",
    "                X_idx,\n",
    "                labels,\n",
    "                metric=idx_dist,\n",
    "                sample_size=1000,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            print(f\"min_samples={min_s:2d}, min_cluster_size={min_cs:2d}, \"\n",
    "                  f\"method={method:5s} → silhouette={sil:.3f}\")\n",
    "            \n",
    "            if sil > best['sil_score']:\n",
    "                best.update({\n",
    "                    'min_samples':      min_s,\n",
    "                    'min_cluster_size': min_cs,\n",
    "                    'method':           method,\n",
    "                    'sil_score':        sil\n",
    "                })\n",
    "\n",
    "print(\"\\n🏆 Best setting:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124ff2c-5487-4207-a435-37ef97710437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Number of samples\n",
    "N = len(abstracts)\n",
    "\n",
    "# 1) Build a numeric “feature” array of shape (N,1) whose only feature is the sample index\n",
    "X_idx = np.arange(N, dtype=int).reshape(-1, 1)\n",
    "\n",
    "# 2) Define a metric that maps back to your command strings\n",
    "def idx_dist(a, b):\n",
    "    # a and b are 1‑d numpy arrays of length 1, dtype float\n",
    "    i = int(a[0])\n",
    "    j = int(b[0])\n",
    "    return dist_fn(abstracts[i], abstracts[j])\n",
    "\n",
    "# 3) Call silhouette_score without precomputing the full D\n",
    "sil = silhouette_score(\n",
    "    X_idx,\n",
    "    labels,\n",
    "    metric=idx_dist,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Approximate silhouette all samples :) : {sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deb1447b-f234-40cb-9b7e-50c94a46f36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 178 is out of bounds for axis 0 with size 178",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 6. Compute overall silhouette score\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# np.fill_diagonal(D, 0)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 4. If you have noise labels (e.g. -1), drop them:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mask \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m D_clean \u001b[38;5;241m=\u001b[39m \u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mix_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m labels_clean \u001b[38;5;241m=\u001b[39m labels[mask]\n\u001b[1;32m     11\u001b[0m sil_avg \u001b[38;5;241m=\u001b[39m silhouette_score(D, labels, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 178 is out of bounds for axis 0 with size 178"
     ]
    }
   ],
   "source": [
    "sil = silhouette_score(D_clean, labels_clean, metric=\"precomputed\")\n",
    "print(f\"Silhouette = {sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483d055c-6423-4484-a317-7cfefd9ada92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22044605e-16, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.22044605e-16, 9.99999999e-01, ...,\n",
       "        9.99999999e-01, 9.99999999e-01, 9.99999999e-01],\n",
       "       [1.00000000e+00, 9.99999999e-01, 2.22044605e-16, ...,\n",
       "        9.99999999e-01, 9.99999999e-01, 9.99999999e-01],\n",
       "       ...,\n",
       "       [1.00000000e+00, 9.99999999e-01, 9.99999999e-01, ...,\n",
       "        2.22044605e-16, 2.22044605e-16, 2.22044605e-16],\n",
       "       [1.00000000e+00, 9.99999999e-01, 9.99999999e-01, ...,\n",
       "        2.22044605e-16, 2.22044605e-16, 2.22044605e-16],\n",
       "       [1.00000000e+00, 9.99999999e-01, 9.99999999e-01, ...,\n",
       "        2.22044605e-16, 2.22044605e-16, 2.22044605e-16]],\n",
       "      shape=(9958, 9958))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9d09de3-ad13-4912-80a5-78d3f1f71a24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Per‐sample silhouette and plot\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sil_vals \u001b[38;5;241m=\u001b[39m silhouette_samples(D, labels, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m y_lower \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# 7. Per‐sample silhouette and plot\n",
    "sil_vals = silhouette_samples(D, labels, metric=\"precomputed\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "y_lower = 10\n",
    "\n",
    "for cluster_id in np.unique(labels):\n",
    "    ith_vals = np.sort(sil_vals[labels == cluster_id])\n",
    "    size    = ith_vals.shape[0]\n",
    "    y_upper = y_lower + size\n",
    "\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_vals, alpha=0.7)\n",
    "    ax.text(-0.05, y_lower + 0.5 * size, str(cluster_id))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.axvline(x=sil_avg, color='red', linestyle='--')\n",
    "ax.set_title(\"Silhouette Plot for FISHDBC Clusters\")\n",
    "ax.set_xlabel(\"Silhouette Coefficient\")\n",
    "ax.set_ylabel(\"Cluster Label\")\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim([-0.1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255854e-c31e-4d2a-b4a6-1994809849fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
